# DB与redis数据一致性如何保证

## 产生的原因：

1.并发的场景下，导致读取老的 DB 数据，更新到缓存中。

2.缓存和 DB 的操作，不在一个事务中，可能只有一个 DB 操作成功，而另一个 Cache 操作失败，导致不一致。

## 方案1：先淘汰缓存，再写数据库

### 问题:
在(删除 Cache 的数据, 和更新 DB 数据)时间之间，恰好有一个请求，我们如果使用被动读，因为此时 DB 数据还是老的，又会将老的数据写入到 Cache 中。

在写请求时，先淘汰缓存之前，先获取该分布式锁。
在读请求时，发现缓存不存在时，先获取分布式锁。

## 方案2：先写数据库，再更新缓存

### 问题

要保证 DB 和缓存的操作，能够在“同一个事务”中，从而实现最终一致性。

### 基于定时任务来实现

首先，写入数据库。
然后，在写入数据库所在的事务中，插入一条记录到任务表。该记录会存储需要更新的缓存 KEY 和 VALUE 。
【异步】最后，定时任务每秒扫描任务表，更新到缓存中，之后删除该记录。

### 基于消息队列来实现（事务消息）

首先，写入数据库。
然后，发送带有缓存 KEY 和 VALUE 的事务消息。此时，需要有支持事务消息特性的消息队列，或者我们自己封装消息队列，支持事务消息。
【异步】最后，消费者消费该消息，更新到缓存中。

### 还存在问题

并发写执行时，先更新成功 DB 的，结果后更新缓存。线程 1 快于线程 2 ，但是实际线程1 晚于线程 2 ，导致数据不一致

方案：
缓存值中，拼接上数据版本号或者时间戳。例如说：value = {value: 原值, version: xxx}

在定时任务或消息队列执行更新缓存时，先读取缓存，对比版本号或时间戳，大于才进行更新。

## 方案3：基于数据库的 binlog 日志

应用直接写数据到数据库中。
数据库更新binlog日志。
利用Canal中间件读取binlog日志。
Canal借助于限流组件按频率将数据发到MQ中。
应用监控MQ通道，将MQ的数据更新到Redis缓存中。

## 方案4：双淘汰机制(大数场景)

使用缓存过程中，经常会遇到缓存数据的不一致性和脏读现象。一般情况下，采取缓存双淘汰机制，
在更新数据库的前淘汰缓存。此外，设定超时时间，例如三十分钟。

极端场景下，即使有脏数据进入缓存，这个脏数据也最存在一段时间后自动销毁。







