# 微服务重要组件 

## 1.微服务基本能力


![image](https://github.com/williamzhang11/fastThinking/blob/master/src/main/java/com/xiu/fastThinking/image/mircoservicemodule.JPG)

## 2.服务注册中心

服务之间需要创建一种服务发现机制，用于帮助服务之间互相感知彼此的存在。服务启动时会将自身的服务信息注册到注册中心
，并订阅自己需要消费的服务。

服务注册中心是服务发现的核心。它保存了各个可用服务实例的网络地址（ip和port）.服务注册中心必须要有高可用性和实时
更新功能。上面提到netflix eureka就是一个服务注册中心。它提供服务注册和查询服务信息的rest api。服务通过
使用post请求注册自己的ip和port.每30秒发送一个put请求刷新注册信息。通过delete请求注销服务。
客户端通过get请求获取可用服务实例信息。

eureka的高可用通过运行多个实例实现，每个eureka服务都有一个弹性ip address.

其他的服务注册中心有：

zookeeper —— 在分布式应用中被广泛使用，高性能的协调服务。 Apache Zookeeper 
最初为Hadoop的一个子项目，但现在是一个顶级项目。

### 2.1 zookeeper服务注册和发现

zookeeper可以充当一个服务注册表（Service Registry），让多个服务提供者形成一个集群
，让服务消费者通过服务注册表获取具体的服务访问地址（ip+端口）去访问具体的服务提供者

![image](https://github.com/williamzhang11/fastThinking/blob/master/src/main/java/com/xiu/fastThinking/image/zookeeperregister.JPG)

具体来说，zookeeper就是个分布式文件系统，每当一个服务提供者部署后都要将自己的服务注册到zookeeper的某一路径上: /{service}/{version}/{ip:port}, 比如我们的HelloWorldService部署到两台机器，
那么zookeeper上就会创建两条目录：分别为/HelloWorldService/1.0.0/100.19.20.01:16888 /HelloWorldService/1.0.0/100.19.20.02:16888。

zookeeper提供了“心跳检测”功能，它会定时向各个服务提供者发送一个请求（实际上建立的是一个 socket 长连接），
如果长期没有响应，服务中心就认为该服务提供者已经“挂了”，并将其剔除，比如100.19.20.02这台机器如果宕机了，那么zookeeper上的路径就会只剩/HelloWorldService/1.0.0/100.19.20.01:16888。

服务消费者会去监听相应路径（/HelloWorldService/1.0.0），一旦路径上的数据有任务变化（增加或减少），
zookeeper都会通知服务消费方服务提供者地址列表已经发生改变，从而进行更新。

zookeeper 与生俱来的容错容灾能力（比如leader选举），可以确保服务注册表的高可用性


## 3. 负载均衡

服务高可用的保证手段，为了保证高可用，每一个微服务都需要部署多个服务实例来提供服务。
此时客户端进行服务的负载均衡。

### 3.1 负载均衡的常见策略

#### 3.1.1 随机
把来自网络的请求随机分配给内部中的多个服务器。

#### 3.1.2 轮询
每一个来自网络中的请求，轮流分配给内部的服务器，从1到N然后重新开始。此
种负载均衡算法适合服务器组内部的服务器都具有相同的配置并且平均服务请求相对均衡的情况。

#### 3.1.3 加权轮询
根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。
例如：服务器A的权值被设计成1，B的权值是3，C的权值是6，则服务器A、B、C将分别接受到10%
、30％、60％的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。

#### 3.1.4 IP Hash
这种方式通过生成请求源IP的哈希值，并通过这个哈希值来找到正确的真实服务器。这意味着对于同一
主机来说他对应的服务器总是相同。使用这种方式，你不需要保存任何源IP。但是需要注意，这种方式可
能导致服务器负载不平衡。

#### 3.1.5 最少连接数
客户端的每一次请求服务在服务器停留的时间可能会有较大的差异，随着工作时间加长，如果采用简单
的轮循或随机均衡算法，每一台服务器上的连接进程可能会产生极大的不同，并没有达到真正的负载均衡。
最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在处理的连接数量，
当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，负载更加
均衡。此种均衡算法适合长时处理的请求服务，如FTP。




## 4.容错

容错，这个词的理解，直面意思就是可以容下错误，不让错误再次扩张，让这个错误产生的
影响在一个固定的边界之内，“千里之堤毁于蚁穴”我们用容错的方式就是让这种蚁穴不要变
大。那么我们常见的降级，限流，熔断器，超时重试等等都是容错的方法。

在调用服务集群时，如果一个微服务调用异常，如超时，连接异常，网络异常等，则根据容错策
略进行服务容错。目前支持的服务容错策略有快速失败，失效切换。如果连续失败多次则直接熔断
，不再发起调用。这样可以避免一个服务异常拖垮所有依赖于他的服务。

### 4.1容错策略

#### 4.1.1 快速失败
服务只发起一次待用，失败立即报错。通常用于非幂等下性的写操作

#### 4.1.2 失效切换
服务发起调用，当出现失败后，重试其他服务器。通常用于读操作，但重
试会带来更长时间的延迟。重试的次数通常是可以设置的

#### 4.1.3 失败安全
失败安全， 当服务调用出现异常时，直接忽略。通常用于写入日志等操作。

#### 4.1.4 失败自动恢复
当服务调用出现异常时，记录失败请求，定时重发。通常用于消息通知。


#### 4.1.5 forking Cluster
并行调用多个服务器，只要有一个成功，即返回。通常用于实时性较高的读操作。可以通过forks=n来设置最大并行数。


#### 4.1.6 广播调用
广播调用所有提供者，逐个调用，任何一台失败则失败。通常用于通知所有提供者更新缓存或日志等本地资源信息。

## 5. 熔断
熔断技术可以说是一种“智能化的容错”，当调用满足失败次数，失败比例就会触发熔断器打开，有程序自动切断当前的RPC调用,来防止错误进一步扩大。实现一个熔断器主要是考虑三种模式，关闭，打开，半开。各个状态的转换如下图。

![image](https://github.com/williamzhang11/fastThinking/blob/master/src/main/java/com/xiu/fastThinking/image/circuitbreak.JPG)

它有以下三种状态：

（1）关闭( Closed )：默认情况下Circuit Breaker是关闭的，此时允许操作执行。CircuitBreaker内部记录着最近失败的次数，如果对应的操作执行失败，次数就会续一次。如果在某个时间段内，失败次数（或者失败比率）达到阈值，CircuitBreaker会转换到开启( Open )状态。在开启状态中，Circuit Breaker会启用一个超时计时器，设这个计时器的目的是给集群相应的时间来恢复故障。当计时器时间到的时候，CircuitBreaker会转换到半开启( Half-Open )状态。


（2）开启( Open )：在此状态下，执行对应的操作将会立即失败并且立即抛出异常。


（3）半开启( Half-Open )：在此状态下，Circuit Breaker会允许执行一定数量的操作。如果所有操作全部成功，CircuitBreaker就会假定故障已经恢复，它就会转换到关闭状态，并且重置失败次数。如果其中 任意一次 操作失败了，Circuit Breaker就会认为故障仍然存在，所以它会转换到开启状态并再次开启计时器（再给系统一些时间使其从失败中恢复）

6. 限流和降级

保证核心服务的稳定性。为了保证核心服务的稳定性，随着访问量的不断增加，需要为系统能够处理
的服务数量设置一个极限阀值，超过这个阀值的请求则直接拒绝。同时，为了保证核心服务的可用，
 可以对否些非核心服务进行降级，通过限制服务的最大访问量进行限流，通过管理控制台对单个微服务进行人工降级
 
 8. API网关
 
 这里说的网关是指API网关，直面意思是将所有API调用统一接入到API网关层，有网关层统一接入和输出。一个
 网关的基本功能有：统一接入、安全防护、协议适配、流量管控、长短链接支持、容错能力。有了网关之后，各
 个API服务提供团队可以专注于自己的的业务逻辑处理，而API网关更专注于安全、流量、路由等问题。
 
 9. 多级缓存
 
 最简单的缓存就是查一次数据库然后将数据写入缓存比如redis中并设置过期时间。
 因为有过期失效因此我们要关注下缓存的穿透率，穿透率大了说明缓存的效果不好。
 
还有一种使用缓存的方式就是将缓存持久化，也就是不设置过期时间，这个就会面临一个数据更新的问题

一般有两种办法

（1）1个是利用时间戳，查询默认以redis为主，每次设置数据的时候放入一个时间戳，每次读取数据的时候
用系统当前时间和上次设置的这个时间戳做对比，比如超过5分钟，那么就再查一次数据库。这样可以保证redis
里面永远有数据，一般是对DB的一种容错方法

（2）还有一个就是真正的让redis做为DB使用。就是图里面画的通过订阅数据库的binlog通过数据异构系
统将数据推送给缓存，同时将将缓存设置为多级.可以通过使用jvmcache作为应用内的一级缓存，一般是体积小，
访问频率大的更适合这种jvmcache方式，将一套redis作为二级remote缓存，另外最外层三级redis作为持久化缓存

10. 超时和重试

超时与重试机制也是容错的一种方法，凡是发生RPC调用的地方，比如读取redis，db，mq等，
因为网络故障或者是所依赖的服务故障，长时间不能返回结果，就会导致线程增加，加大cpu负载，
甚至导致雪崩。所以对每一个RPC调用都要设置超时时间。

对于强依赖RPC调用资源的情况，还要有重试机制，但是重试的次数建议1-2次，另外如果有重试，
那么超时时间就要相应的调小，比如重试1次，那么一共是发生2次调用。如果超时时间配置的是2s，
那么客户端就要等待4s才能返回。因此重试+超时的方式，超时时间要调小

11.线程池隔离

线程隔离的之间优势就是防止级联故障，甚至是雪崩。当网关调用N多个接口服务的时候，我们要对每个
接口进行线程隔离。比如，我们有调用订单、商品、用户。那么订单的业务不能够影响到商品和用户的请求
处理。如果不做线程隔离，当访问订单服务出现网络故障导致延时，线程积压最终导致整个服务CPU负载满。
就是我们说的服务全部不可用了，有多少机器都会被此刻的请求塞满。那么有了线程隔离就会使得我们的网关
能保证局部问题不会影响全局。

12. 降级和限流

降级限流的方法业界都已经有很成熟的方法了，比如FAILBACK机制，限流的方法令牌桶，漏桶，信号量等

降级一般都是由统一配置中心的降级开关来实现的，那么当有很多个接口来自同一个提供方，这个提供方的系统
或这机器所在机房网络出现了问题，我们就要有一个统一的降级开关，不然就要一个接口一个接口的来降级。也就
是要对业务类型有一个大闸刀。还有就是 降级切记暴力降级，什么是暴力降级的，比如把论坛功能降调，结果用户
显示一个大白板，我们要实现缓存住一些数据，也就是有托底数据

限流一般分为分布式限流和单机限流，如果实现分布式限流的话就要一个公共的后端存储服务比如redis，在大nginx
节点上利用lua读取redis配置信息

13. 网关监控和统计

 API网关是一个串行的调用，那么每一步发生的异常要记录下来，统一存储到一个地方比如
 elasticserach中，便于后续对调用异常的分析。鉴于公司docker申请都是统一分配，
 而且分配之前docker上已经存在3个agent了，不再允许增加。我们自己实现了一个agent
 程序，来负责采集服务器上面的日志输出，然后发送到kafka集群，再消费到elasticserach中，
 通过web查询。现在做的追踪功能还比较简单，这块还需要继续丰富。
 
 http://www.iocoder.cn/Geek/Learn-micro-services-from-zero/What-is-a-micro-service/







 
 



























